{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sh\n",
      "  Using cached sh-1.14.1-py2.py3-none-any.whl (40 kB)\n",
      "Installing collected packages: sh\n",
      "Successfully installed sh-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "imports_20150407.ipynb:26: MatplotlibDeprecationWarning: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "  \"jupyter\": {\n"
     ]
    }
   ],
   "source": [
    "%run imports.ipynb\n",
    "from os.path import join, isdir, isfile\n",
    "import sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_fn = \"samples.meta.txt\"\n",
    "dat = pd.read_csv(meta_fn, sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_code</th>\n",
       "      <th>population</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "      <th>site</th>\n",
       "      <th>contributor</th>\n",
       "      <th>contact</th>\n",
       "      <th>year</th>\n",
       "      <th>m_s</th>\n",
       "      <th>sex</th>\n",
       "      <th>n_sequences</th>\n",
       "      <th>mean_coverage</th>\n",
       "      <th>ebi_sample_acc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ox_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA0040-C</th>\n",
       "      <td>Twifo_Praso__E2</td>\n",
       "      <td>GHcol</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Twifo Praso</td>\n",
       "      <td>Twifo Praso</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>95033368</td>\n",
       "      <td>30.99</td>\n",
       "      <td>ERS311878</td>\n",
       "      <td>5.60858</td>\n",
       "      <td>-1.54926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA0041-C</th>\n",
       "      <td>Twifo_Praso__H3</td>\n",
       "      <td>GHcol</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Twifo Praso</td>\n",
       "      <td>Twifo Praso</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>95843804</td>\n",
       "      <td>31.70</td>\n",
       "      <td>ERS311886</td>\n",
       "      <td>5.60858</td>\n",
       "      <td>-1.54926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA0042-C</th>\n",
       "      <td>Takoradi_C7</td>\n",
       "      <td>GHcol</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Takoradi</td>\n",
       "      <td>Takoradi</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>107420666</td>\n",
       "      <td>35.65</td>\n",
       "      <td>ERS311894</td>\n",
       "      <td>4.91217</td>\n",
       "      <td>-1.77397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA0043-C</th>\n",
       "      <td>Takoradi_H8</td>\n",
       "      <td>GHcol</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Takoradi</td>\n",
       "      <td>Takoradi</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>95993752</td>\n",
       "      <td>29.46</td>\n",
       "      <td>ERS311902</td>\n",
       "      <td>4.91217</td>\n",
       "      <td>-1.77397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA0044-C</th>\n",
       "      <td>Takoradi_D10</td>\n",
       "      <td>GHcol</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>Takoradi</td>\n",
       "      <td>Takoradi</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>103044262</td>\n",
       "      <td>33.67</td>\n",
       "      <td>ERS311910</td>\n",
       "      <td>4.91217</td>\n",
       "      <td>-1.77397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY0087-C</th>\n",
       "      <td>Tia_dPM_46</td>\n",
       "      <td>CIcol</td>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>101458232</td>\n",
       "      <td>32.56</td>\n",
       "      <td>ERS311822</td>\n",
       "      <td>5.89839</td>\n",
       "      <td>-4.82293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY0088-C</th>\n",
       "      <td>Tia_dPM_52</td>\n",
       "      <td>CIcol</td>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>95140584</td>\n",
       "      <td>30.75</td>\n",
       "      <td>ERS311830</td>\n",
       "      <td>5.89839</td>\n",
       "      <td>-4.82293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY0089-C</th>\n",
       "      <td>Tia_aPM_4</td>\n",
       "      <td>CIcol</td>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>92383724</td>\n",
       "      <td>29.04</td>\n",
       "      <td>ERS311838</td>\n",
       "      <td>5.89839</td>\n",
       "      <td>-4.82293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY0090-C</th>\n",
       "      <td>Tia_aPM_13</td>\n",
       "      <td>CIcol</td>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>96210618</td>\n",
       "      <td>30.94</td>\n",
       "      <td>ERS311846</td>\n",
       "      <td>5.89839</td>\n",
       "      <td>-4.82293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY0091-C</th>\n",
       "      <td>Tia_aPM_37</td>\n",
       "      <td>CIcol</td>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>Tiassale</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>David Weetman</td>\n",
       "      <td>2012</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>95973872</td>\n",
       "      <td>31.30</td>\n",
       "      <td>ERS311854</td>\n",
       "      <td>5.89839</td>\n",
       "      <td>-4.82293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 src_code population        country     location         site  \\\n",
       "ox_code                                                                         \n",
       "AA0040-C  Twifo_Praso__E2      GHcol          Ghana  Twifo Praso  Twifo Praso   \n",
       "AA0041-C  Twifo_Praso__H3      GHcol          Ghana  Twifo Praso  Twifo Praso   \n",
       "AA0042-C      Takoradi_C7      GHcol          Ghana     Takoradi     Takoradi   \n",
       "AA0043-C      Takoradi_H8      GHcol          Ghana     Takoradi     Takoradi   \n",
       "AA0044-C     Takoradi_D10      GHcol          Ghana     Takoradi     Takoradi   \n",
       "...                   ...        ...            ...          ...          ...   \n",
       "AY0087-C       Tia_dPM_46      CIcol  Cote d'Ivoire     Tiassale     Tiassale   \n",
       "AY0088-C       Tia_dPM_52      CIcol  Cote d'Ivoire     Tiassale     Tiassale   \n",
       "AY0089-C        Tia_aPM_4      CIcol  Cote d'Ivoire     Tiassale     Tiassale   \n",
       "AY0090-C       Tia_aPM_13      CIcol  Cote d'Ivoire     Tiassale     Tiassale   \n",
       "AY0091-C       Tia_aPM_37      CIcol  Cote d'Ivoire     Tiassale     Tiassale   \n",
       "\n",
       "            contributor        contact  year m_s sex  n_sequences  \\\n",
       "ox_code                                                             \n",
       "AA0040-C  David Weetman  David Weetman  2012   M   F     95033368   \n",
       "AA0041-C  David Weetman  David Weetman  2012   M   F     95843804   \n",
       "AA0042-C  David Weetman  David Weetman  2012   M   F    107420666   \n",
       "AA0043-C  David Weetman  David Weetman  2012   M   F     95993752   \n",
       "AA0044-C  David Weetman  David Weetman  2012   M   F    103044262   \n",
       "...                 ...            ...   ...  ..  ..          ...   \n",
       "AY0087-C  David Weetman  David Weetman  2012   M   F    101458232   \n",
       "AY0088-C  David Weetman  David Weetman  2012   M   F     95140584   \n",
       "AY0089-C  David Weetman  David Weetman  2012   M   F     92383724   \n",
       "AY0090-C  David Weetman  David Weetman  2012   M   F     96210618   \n",
       "AY0091-C  David Weetman  David Weetman  2012   M   F     95973872   \n",
       "\n",
       "          mean_coverage ebi_sample_acc  latitude  longitude  \n",
       "ox_code                                                      \n",
       "AA0040-C          30.99      ERS311878   5.60858   -1.54926  \n",
       "AA0041-C          31.70      ERS311886   5.60858   -1.54926  \n",
       "AA0042-C          35.65      ERS311894   4.91217   -1.77397  \n",
       "AA0043-C          29.46      ERS311902   4.91217   -1.77397  \n",
       "AA0044-C          33.67      ERS311910   4.91217   -1.77397  \n",
       "...                 ...            ...       ...        ...  \n",
       "AY0087-C          32.56      ERS311822   5.89839   -4.82293  \n",
       "AY0088-C          30.75      ERS311830   5.89839   -4.82293  \n",
       "AY0089-C          29.04      ERS311838   5.89839   -4.82293  \n",
       "AY0090-C          30.94      ERS311846   5.89839   -4.82293  \n",
       "AY0091-C          31.30      ERS311854   5.89839   -4.82293  \n",
       "\n",
       "[505 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = dat[dat.population != 'AOcol'] \n",
    "dat = dat[dat.population != 'CMgam'] \n",
    "dat = dat[dat.population != 'FRgam'] \n",
    "dat = dat[dat.population != 'GAgam'] \n",
    "dat = dat[dat.population != 'GQgam'] \n",
    "dat = dat[dat.population != 'KE'] \n",
    "dat = dat[dat.population != 'UGgam'] \n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_selection = metadata.population.isin({'GHcol', 'GHgam', 'BFgam', 'BFcol', 'GM', 'GW', 'GNgam', 'GNcol',\n",
    "       'CIcol'}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset_fn = callset_biallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_min = 0.01\n",
    "r2_value = 0.1\n",
    "downsample_n = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "## 3R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = callset_fn['3R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh_samples = [str(s) for s in callset_fn['3R'][\"samples\"][:]]\n",
    "fh_samples = list(compress(fh_samples, pop_selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(compress(fh_samples, pop_selection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;GenotypeChunkedArray shape=(10752701, 505, 2) dtype=int8 chunks=(5251, 505, 2)\n",
       "   nbytes=10.1G cbytes=472.9M cratio=21.9\n",
       "   compression=blosc compression_opts={'cname': 'lz4', 'clevel': 5, 'shuffle': 1, 'blocksize': 0}\n",
       "   values=zarr.core.Array&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th><th style=\"text-align: center\">3</th><th style=\"text-align: center\">4</th><th style=\"text-align: center\">...</th><th style=\"text-align: center\">500</th><th style=\"text-align: center\">501</th><th style=\"text-align: center\">502</th><th style=\"text-align: center\">503</th><th style=\"text-align: center\">504</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">2</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">...</th><td style=\"text-align: center\" colspan=\"12\">...</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">10752698</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">10752699</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">10752700</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<GenotypeChunkedArray shape=(10752701, 505, 2) dtype=int8 chunks=(5251, 505, 2)\n",
       "   nbytes=10.1G cbytes=472.9M cratio=21.9\n",
       "   compression=blosc compression_opts={'cname': 'lz4', 'clevel': 5, 'shuffle': 1, 'blocksize': 0}\n",
       "   values=zarr.core.Array>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = allel.GenotypeChunkedArray(fh['calldata/GT']).subset(sel1=pop_selection)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = fh['variants']['POS'][:]\n",
    "loci = (positions >= 1) & (positions <= 24_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g =g.compress(loci, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.compress(loci, positions)\n",
    "positions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alleles = g.count_alleles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "biallelic = alleles.max_allele() <= 1\n",
    "g = g.compress(biallelic, axis=0)\n",
    "pos = np.compress(np.array(biallelic), pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = g.count_alleles().to_frequencies()\n",
    "maf_ok = np.min(np.array(freqs), axis=1) >= maf_min\n",
    "g = g.compress(maf_ok, axis=0)\n",
    "pos = np.compress(maf_ok, pos, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling... to 100000 from 865193\n"
     ]
    }
   ],
   "source": [
    "if pos.size > downsample_n:\n",
    "        print(\"Downsampling... to {0} from {1}\".format(downsample_n, pos.size))\n",
    "        idx = np.random.choice(np.arange(0, pos.size), downsample_n, False)\n",
    "        idx.sort()\n",
    "        pos = np.take(pos, idx)\n",
    "        g = g.take(idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;GenotypeChunkedArray shape=(100000, 505, 2) dtype=int8 chunks=(782, 505, 2)\n",
       "   nbytes=96.3M cbytes=20.3M cratio=4.8\n",
       "   compression=blosc compression_opts={'cname': 'lz4', 'clevel': 5, 'shuffle': 1, 'blocksize': 0}\n",
       "   values=zarr.core.Array&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th><th style=\"text-align: center\">3</th><th style=\"text-align: center\">4</th><th style=\"text-align: center\">...</th><th style=\"text-align: center\">500</th><th style=\"text-align: center\">501</th><th style=\"text-align: center\">502</th><th style=\"text-align: center\">503</th><th style=\"text-align: center\">504</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">2</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">...</th><td style=\"text-align: center\" colspan=\"12\">...</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">99997</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">99998</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">99999</th><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<GenotypeChunkedArray shape=(100000, 505, 2) dtype=int8 chunks=(782, 505, 2)\n",
       "   nbytes=96.3M cbytes=20.3M cratio=4.8\n",
       "   compression=blosc compression_opts={'cname': 'lz4', 'clevel': 5, 'shuffle': 1, 'blocksize': 0}\n",
       "   values=zarr.core.Array>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_3R = g\n",
    "g_3R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('chrom_3R_downs.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"3R\": shape (100000, 505, 2), type \"|i1\">"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5f.create_dataset('3R', data=g_3R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import h5py\n",
    "import allel\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--pedigree', '-P'], dest='pedigree', nargs=None, const=None, default=None, type=None, choices=None, help='path to load pedigree file', metavar=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_consecutive_true(a):\n",
    "    if a.sum() == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.diff(np.where(\n",
    "            np.concatenate(([a[0]], a[:-1] != a[1:], [True])))[0])[::2].max()\n",
    "\n",
    "chunk_size = 100000\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Tool to produce a vcf file from an hdf5 file')\n",
    "\n",
    "parser.add_argument('input', help='input hdf5 file')\n",
    "parser.add_argument('output', help='output file stem')\n",
    "\n",
    "parser.add_argument('--filtermissing', '-F', action='store_false', default=True,\n",
    "                    dest='keepmissing')\n",
    "parser.add_argument('--cutoff', '-C', action='store', default=0.04,\n",
    "                    dest='missingcutoff', type=float,\n",
    "                    help='Maximum missing GTs tolerated in a sample')\n",
    "parser.add_argument('--pedigree', '-P', action='store', dest='pedigree',\n",
    "                    help='path to load pedigree file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--filtermissing] [--cutoff MISSINGCUTOFF]\n",
      "                             [--pedigree PEDIGREE]\n",
      "                             input output\n",
      "ipykernel_launcher.py: error: the following arguments are required: output\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# to do: add option to only filter individual crosses.\n",
    "args = parser.parse_args()\n",
    "\n",
    "with h5py.File('chrom_3R_downs.h5', mode='r') as h5_handle:\n",
    "    with gzip.open(args.output + '.vcf.gz', 'wb') as f:\n",
    "\n",
    "        f.write(b'##fileformat=VCFv4.1\\n')\n",
    "        f.write(b'##FORMAT=<ID=GT,Number=1,Type=String,'\n",
    "                b'Description=\"Genotype\">\\n')\n",
    "        f.write(b'##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Allele count'\n",
    "                b'in genotypes, for each ALT allele, in the same order as'\n",
    "                b'listed\">\\n')\n",
    "\n",
    "        f.write(b'##contig=<ID=2L,length=49364325>\\n')\n",
    "        f.write(b'##contig=<ID=2R,length=61545105>\\n')\n",
    "        f.write(b'##contig=<ID=3L,length=41963435>\\n')\n",
    "        f.write(b'##contig=<ID=3R,length=53200684>\\n')\n",
    "        f.write(b'##contig=<ID=UNKN,length=42389979>\\n')\n",
    "        f.write(b'##contig=<ID=X,length=24393108>\\n')\n",
    "        f.write(b'##contig=<ID=Y_unplaced,length=237045>\\n')\n",
    "        f.write(b'##reference=file:///data/anopheles/ag1000g/data/genome/AgamP3'\n",
    "                b'/Anopheles-gambiae-PEST_CHROMOSOMES_AgamP3.fa\\n')\n",
    "\n",
    "        reqd = [b'#CHROM', b'POS', b'ID', b'REF', b'ALT',\n",
    "                b'QUAL', b'FILTER', b'INFO', b'FORMAT']\n",
    "\n",
    "        # rememeber to act on all 1st level keys!\n",
    "        # does not support multiple chromosomes currently!\n",
    "        # Actually should probably add to filter script...\n",
    "        assert len(h5_handle.keys()) <= 1\n",
    "        for k in h5_handle.keys():\n",
    "\n",
    "            samples = h5_handle[k]['samples'][:].tolist()\n",
    "            missing_rates = np.zeros(len(samples))\n",
    "            ok_samples = np.ones(len(samples), dtype=\"bool\")\n",
    "\n",
    "            gt = allel.GenotypeChunkedArray(\n",
    "                h5_handle[k]['calldata/genotype'][:])\n",
    "\n",
    "            if not args.keepmissing:\n",
    "\n",
    "                missing_gt = gt.is_missing()\n",
    "\n",
    "                for i, s in enumerate(samples):\n",
    "\n",
    "                    consecutive_miss = get_consecutive_true(missing_gt[:, i])\n",
    "                    miss_rate_i = consecutive_miss/float(missing_gt.shape[0])\n",
    "\n",
    "                    print(\"Missing rate of\", s, ':',\n",
    "                          \"{:.8f}\".format(miss_rate_i),\n",
    "                          \"({0}/{1})\".format(i+1, len(samples)))\n",
    "                    missing_rates[i] = miss_rate_i\n",
    "\n",
    "                print(\"Rate max:\", missing_rates.max())\n",
    "                ok_samples = missing_rates < args.missingcutoff\n",
    "\n",
    "                if np.any(~ok_samples):\n",
    "                    msg = \"The following {0} samples are excluded as they \" \\\n",
    "                          \"have a consecutive missing gt run of >= {1} of \" \\\n",
    "                          \"all calls:\".format(str(np.sum(~ok_samples)),\n",
    "                                              str(args.missingcutoff))\n",
    "                    print(msg)\n",
    "\n",
    "                    for sa, rt in zip(\n",
    "                            np.compress(~ok_samples, samples).tolist(),\n",
    "                            np.compress(~ok_samples, missing_rates).tolist()):\n",
    "                        print(sa + \": \" + str(rt))\n",
    "\n",
    "                    samples = [s.decode() for s in np.compress(\n",
    "                        ok_samples, samples).tolist()]\n",
    "                else:\n",
    "                    print(\"All samples meet the missingness run threshold ({0})\"\n",
    "                          .format(str(args.missingcutoff)))\n",
    "\n",
    "            if args.pedigree is not None:\n",
    "                phasing.utils.create_samples_file(args.pedigree,\n",
    "                                                  args.output + '.sample',\n",
    "                                                  samples)\n",
    "\n",
    "            f.write(b\"\\t\".join(reqd + samples) + b\"\\n\")\n",
    "\n",
    "            number_variants = h5_handle[k]['variants']['POS'][:].size\n",
    "            chunks = np.arange(0, number_variants + chunk_size, chunk_size)\n",
    "            assert chunks.max() > number_variants\n",
    "\n",
    "            for start, stop in zip(chunks[:-1], chunks[1:]):\n",
    "                sl = slice(start, stop)\n",
    "                positions = h5_handle[k]['variants']['POS'][sl]\n",
    "                reference = h5_handle[k]['variants']['REF'][sl]\n",
    "                alternate = h5_handle[k]['variants']['ALT'][sl]\n",
    "                genotypes = h5_handle[k]['calldata']['genotype'][sl]\n",
    "                genotypes = np.compress(ok_samples, genotypes, axis=1)\n",
    "                multiple_alts = alternate.ndim > 1\n",
    "\n",
    "                for pos, ref, alt, gt in zip(positions, reference,\n",
    "                                             alternate, genotypes):\n",
    "                    filterstring = 'PASS'\n",
    "                    # This line filters variants where ALL genotypes are missing\n",
    "                    if not args.keepmissing and np.all(gt == -1):\n",
    "                        continue\n",
    "\n",
    "                    # alt may be an np array, with several entries.\n",
    "                    if multiple_alts:\n",
    "                        alt = b\",\".join(x for x in alt if x != b'')\n",
    "\n",
    "                    try:\n",
    "                        gstr = np.apply_along_axis(b\"/\".join, axis=1,\n",
    "                                                   arr=gt.astype(\"a2\"))\n",
    "\n",
    "                        genotype_str = b\"\\t\".join([s for s in gstr]) + b\"\\n\"\n",
    "                        genotype_str = genotype_str.replace(b\"-1/-1\", b\"./.\")\n",
    "\n",
    "                        line = b\"\\t\".join(\n",
    "                            [k.encode(), str(pos).encode()] +\n",
    "                            [b'.', ref, alt, b'0', b'.', b'.', b'GT'] +\n",
    "                            [genotype_str])\n",
    "\n",
    "                        f.write(line)\n",
    "\n",
    "                    except TypeError:\n",
    "                        print(pos)\n",
    "                        print(ref)\n",
    "                        print(alt)\n",
    "                        print(gt)\n",
    "                        raise TypeError(\"Some data wasn't of the correct type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import h5py\n",
    "import allel\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "\n",
    "def get_consecutive_true(a):\n",
    "    if a.sum() == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.diff(np.where(\n",
    "            np.concatenate(([a[0]], a[:-1] != a[1:], [True])))[0])[::2].max()\n",
    "\n",
    "chunk_size = 200000\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Tool to produce a vcf file from an hdf5 file')\n",
    "\n",
    "parser.add_argument('input', help='input hdf5 file')\n",
    "parser.add_argument('output', help='output file stem')\n",
    "\n",
    "parser.add_argument('--filtermissing', '-F', action='store_false', default=True,\n",
    "                    dest='keepmissing')\n",
    "parser.add_argument('--cutoff', '-C', action='store', default=0.04,\n",
    "                    dest='missingcutoff', type=float,\n",
    "                    help='Maximum missing GTs tolerated in a sample')\n",
    "parser.add_argument('--pedigree', '-P', action='store', dest='pedigree',\n",
    "                    help='path to load pedigree file')\n",
    "\n",
    "# to do: add option to only filter individual crosses.\n",
    "args = parser.parse_args()\n",
    "\n",
    "with h5py.File(args.input, mode='r') as h5_handle:\n",
    "    with gzip.open(args.output + '.vcf.gz', 'wb') as f:\n",
    "\n",
    "        f.write(b'##fileformat=VCFv4.1\\n')\n",
    "        f.write(b'##FORMAT=<ID=GT,Number=1,Type=String,'\n",
    "                b'Description=\"Genotype\">\\n')\n",
    "        f.write(b'##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Allele count'\n",
    "                b'in genotypes, for each ALT allele, in the same order as'\n",
    "                b'listed\">\\n')\n",
    "\n",
    "        f.write(b'##contig=<ID=2L,length=49364325>\\n')\n",
    "        f.write(b'##contig=<ID=2R,length=61545105>\\n')\n",
    "        f.write(b'##contig=<ID=3L,length=41963435>\\n')\n",
    "        f.write(b'##contig=<ID=3R,length=53200684>\\n')\n",
    "        f.write(b'##contig=<ID=UNKN,length=42389979>\\n')\n",
    "        f.write(b'##contig=<ID=X,length=24393108>\\n')\n",
    "        f.write(b'##contig=<ID=Y_unplaced,length=237045>\\n')\n",
    "        f.write(b'##reference=file:///data/anopheles/ag1000g/data/genome/AgamP3'\n",
    "                b'/Anopheles-gambiae-PEST_CHROMOSOMES_AgamP3.fa\\n')\n",
    "\n",
    "        reqd = [b'#CHROM', b'POS', b'ID', b'REF', b'ALT',\n",
    "                b'QUAL', b'FILTER', b'INFO', b'FORMAT']\n",
    "\n",
    "        # rememeber to act on all 1st level keys!\n",
    "        # does not support multiple chromosomes currently!\n",
    "        # Actually should probably add to filter script...\n",
    "        assert len(h5_handle.keys()) <= 1\n",
    "        for k in h5_handle.keys():\n",
    "\n",
    "            samples = h5_handle[k]['samples'][:].tolist()\n",
    "            missing_rates = np.zeros(len(samples))\n",
    "            ok_samples = np.ones(len(samples), dtype=\"bool\")\n",
    "\n",
    "            gt = allel.GenotypeChunkedArray(\n",
    "                h5_handle[k]['calldata/genotype'][:])\n",
    "\n",
    "            if not args.keepmissing:\n",
    "\n",
    "                missing_gt = gt.is_missing()\n",
    "\n",
    "                for i, s in enumerate(samples):\n",
    "\n",
    "                    consecutive_miss = get_consecutive_true(missing_gt[:, i])\n",
    "                    miss_rate_i = consecutive_miss/float(missing_gt.shape[0])\n",
    "\n",
    "                    print(\"Missing rate of\", s, ':',\n",
    "                          \"{:.8f}\".format(miss_rate_i),\n",
    "                          \"({0}/{1})\".format(i+1, len(samples)))\n",
    "                    missing_rates[i] = miss_rate_i\n",
    "\n",
    "                print(\"Rate max:\", missing_rates.max())\n",
    "                ok_samples = missing_rates < args.missingcutoff\n",
    "\n",
    "                if np.any(~ok_samples):\n",
    "                    msg = \"The following {0} samples are excluded as they \" \\\n",
    "                          \"have a consecutive missing gt run of >= {1} of \" \\\n",
    "                          \"all calls:\".format(str(np.sum(~ok_samples)),\n",
    "                                              str(args.missingcutoff))\n",
    "                    print(msg)\n",
    "\n",
    "                    for sa, rt in zip(\n",
    "                            np.compress(~ok_samples, samples).tolist(),\n",
    "                            np.compress(~ok_samples, missing_rates).tolist()):\n",
    "                        print(sa + \": \" + str(rt))\n",
    "\n",
    "                    samples = [s.decode() for s in np.compress(\n",
    "                        ok_samples, samples).tolist()]\n",
    "                else:\n",
    "                    print(\"All samples meet the missingness run threshold ({0})\"\n",
    "                          .format(str(args.missingcutoff)))\n",
    "\n",
    "            if args.pedigree is not None:\n",
    "                phasing.utils.create_samples_file(args.pedigree,\n",
    "                                                  args.output + '.sample',\n",
    "                                                  samples)\n",
    "\n",
    "            f.write(b\"\\t\".join(reqd + samples) + b\"\\n\")\n",
    "\n",
    "            number_variants = h5_handle[k]['variants']['POS'][:].size\n",
    "            chunks = np.arange(0, number_variants + chunk_size, chunk_size)\n",
    "            assert chunks.max() > number_variants\n",
    "\n",
    "            for start, stop in zip(chunks[:-1], chunks[1:]):\n",
    "                sl = slice(start, stop)\n",
    "                positions = h5_handle[k]['variants']['POS'][sl]\n",
    "                reference = h5_handle[k]['variants']['REF'][sl]\n",
    "                alternate = h5_handle[k]['variants']['ALT'][sl]\n",
    "                genotypes = h5_handle[k]['calldata']['genotype'][sl]\n",
    "                genotypes = np.compress(ok_samples, genotypes, axis=1)\n",
    "                multiple_alts = alternate.ndim > 1\n",
    "\n",
    "                for pos, ref, alt, gt in zip(positions, reference,\n",
    "                                             alternate, genotypes):\n",
    "                    filterstring = 'PASS'\n",
    "                    # This line filters variants where ALL genotypes are missing\n",
    "                    if not args.keepmissing and np.all(gt == -1):\n",
    "                        continue\n",
    "\n",
    "                    # alt may be an np array, with several entries.\n",
    "                    if multiple_alts:\n",
    "                        alt = b\",\".join(x for x in alt if x != b'')\n",
    "\n",
    "                    try:\n",
    "                        gstr = np.apply_along_axis(b\"/\".join, axis=1,\n",
    "                                                   arr=gt.astype(\"a2\"))\n",
    "\n",
    "                        genotype_str = b\"\\t\".join([s for s in gstr]) + b\"\\n\"\n",
    "                        genotype_str = genotype_str.replace(b\"-1/-1\", b\"./.\")\n",
    "\n",
    "                        line = b\"\\t\".join(\n",
    "                            [k.encode(), str(pos).encode()] +\n",
    "                            [b'.', ref, alt, b'0', b'.', b'.', b'GT'] +\n",
    "                            [genotype_str])\n",
    "\n",
    "                        f.write(line)\n",
    "\n",
    "                    except TypeError:\n",
    "                        print(pos)\n",
    "                        print(ref)\n",
    "                        print(alt)\n",
    "                        print(gt)\n",
    "                        raise TypeError(\"Some data wasn't of the correct type.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
