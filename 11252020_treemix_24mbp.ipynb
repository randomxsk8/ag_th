{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treemix Ag1000G phase2\n",
    "For build a dataset Treemix I need unlinked SNPs. So I have to prune my allele count datasets to obtain SNPs in high LD.\n",
    "For doing this I need:\n",
    "    - Phase2 Genotype callset\n",
    "    - Phase2 Allele count\n",
    "    - Outgroup Allele count\n",
    "\n",
    "In this notebook I edited an old Alistair's notebook of the Phase1 of Ag1000G (<b>20151001 treemix prep 4</b>). On my phase2 datasets I have already the biallelic allele counts so I skipped the searching and filtering for biallelic SNPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import my modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "imports_20150407.ipynb:26: MatplotlibDeprecationWarning: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "  \"outputs_hidden\": false\n"
     ]
    }
   ],
   "source": [
    "%run imports.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import callsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset_pass= callset_biallel\n",
    "allele_counts= zarr.open('../data/phase2_biallel_allele_count.zarr/')\n",
    "outgroup_allele_counts= zarr.open('../data/outgroup_alleles_phase2.zarr/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to locate biallelic allele counts on a range for my outgroup and phase2 datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outgroup_ascertainment(chrom, start, stop, outgroups):\n",
    "    \n",
    "    # locate region\n",
    "    pos = allel.SortedIndex(callset_pass[chrom]['variants']['POS'][:])\n",
    "    locr = pos.locate_range(start, stop)\n",
    "    \n",
    "    # ascertain SNPs\n",
    "    loca = np.zeros(pos.shape, dtype='b1')\n",
    "    loca[locr] = True\n",
    "    log('outgroup ascertainment, initial', nnz(loca))\n",
    "    for s in outgroups:\n",
    "        ac = allel.AlleleCountsArray(outgroup_allele_counts[chrom][s][:])\n",
    "        # non-missing\n",
    "        locs = (ac.sum(axis=1) > 0)\n",
    "        loca &= locs\n",
    "        log(s, nnz(loca))\n",
    "        \n",
    "    return loca\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingroup_ascertainment(chrom, start, stop, segpops):\n",
    "\n",
    "    # locate region\n",
    "    pos = allel.SortedIndex(callset_pass[chrom]['variants']['POS'][:])\n",
    "    locr = pos.locate_range(start, stop)\n",
    "\n",
    "    # ascertain SNPs\n",
    "    loca = np.zeros(pos.shape, dtype='b1')\n",
    "    loca[locr] = True\n",
    "    log('ingroup ascertainment, initial', nnz(loca))\n",
    "\n",
    "    \n",
    "    # require segregating\n",
    "    for pop in segpops:\n",
    "        ac = allel.AlleleCountsArray(allele_counts[chrom][pop][:])\n",
    "        loc_seg = ac.min(axis=1) > 0\n",
    "        loca &= loc_seg\n",
    "        log('after require segregating in', pop, nnz(loca))\n",
    "        \n",
    "    return loca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for ld pruning. LD-pruning remove SNPs with an high correlation. Using windows this function compute pairwise LD between all SNPs within each window, then removing one SNP from each correlated pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for generating treemix file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_treemix(acs, fn):\n",
    "    pops = sorted(acs.keys())\n",
    "    n_variants = acs[pops[0]].shape[0]\n",
    "    n_alleles = acs[pops[0]].shape[1]\n",
    "    assert n_alleles == 2, 'only biallelic variants supported'\n",
    "    for pop in pops[1:]:\n",
    "        assert n_variants == acs[pop].shape[0], 'bad number of variants for pop %s' % pop\n",
    "        assert n_alleles == acs[pop].shape[1], 'bad number of alleles for pop %s' % pop\n",
    "        \n",
    "    with open(fn, 'wt', encoding='ascii') as f:\n",
    "        print(' '.join(pops), file=f)\n",
    "        for i in range(n_variants):\n",
    "            print(' '.join([','.join(map(str, acs[pop][i])) for pop in pops]), file=f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new function that randomly downsample if I have a large dataset and applies ld-pruning on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_and_prune(chrom, start, stop, loc_asc,\n",
    "                         n=100000, ldp_size=500, ldp_step=250, ldp_threshold=.1, ldp_n_iter=1):\n",
    "\n",
    "    # all variant positions\n",
    "    pos = allel.SortedIndex(callset_pass[chrom]['variants']['POS'][:])\n",
    "    posa = pos[loc_asc]\n",
    "\n",
    "    # randomly downsample\n",
    "    if n < posa.shape[0]:\n",
    "        posds = np.random.choice(posa, n, replace=False)\n",
    "        posds.sort()\n",
    "        posds = allel.SortedIndex(posds)\n",
    "    else:\n",
    "        # skip downsampling\n",
    "        posds = posa\n",
    "    locds = pos.locate_keys(posds)    \n",
    "\n",
    "    # load genotype data\n",
    "    genotype = allel.GenotypeChunkedArray(callset_pass[chrom]['calldata/GT'])\n",
    "    geno_subset = genotype.subset(sel0=loc_asc)\n",
    "    gn = geno_subset.to_n_alt()\n",
    "\n",
    "    \n",
    "    # prune    \n",
    "    for i in range(ldp_n_iter):\n",
    "        loc_unlinked = allel.locate_unlinked(gn, size=ldp_size, step=ldp_step, threshold=ldp_threshold)\n",
    "        n = np.count_nonzero(loc_unlinked)\n",
    "        n_remove = gn.shape[0] - n\n",
    "        log('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "        gnu = gn.compress(loc_unlinked, axis=0)\n",
    "        posu = pos.compress(loc_unlinked)\n",
    "        locu = pos.locate_keys(posu)\n",
    "\n",
    "    return locu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define last function, the analysis function that includes all function below and applies these on my populations, outgroups, chromosomes of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(rname, chrom, start, stop, outgroups, segpops,\n",
    "                 n=100000, ldp_size=500, ldp_step=250, ldp_threshold=.1, ldp_n_iter=1):\n",
    "\n",
    "    # initial ascertainment\n",
    "    loc_og_asc = outgroup_ascertainment(chrom, start, stop, outgroups=outgroups)\n",
    "    loc_ig_asc = ingroup_ascertainment(chrom, start, stop, segpops=segpops)\n",
    "    loc_asc = loc_og_asc & loc_ig_asc\n",
    "    log('initial ascertainment', nnz(loc_asc))\n",
    "    \n",
    "    # downsample and prune\n",
    "    locu = downsample_and_prune(chrom, start, stop, loc_asc, \n",
    "                                n=n, ldp_size=ldp_size, ldp_step=ldp_step, \n",
    "                                ldp_threshold=ldp_threshold, ldp_n_iter=ldp_n_iter)\n",
    "    \n",
    "    # write allele counts\n",
    "    acsu = dict()\n",
    "    for pop in segpops:\n",
    "        acsu[pop] = allele_counts[chrom][pop][:, :2][locu]\n",
    "    for pop in outgroups:\n",
    "        acsu[pop] = outgroup_allele_counts[chrom][pop][:, :2][locu]\n",
    "\n",
    "    outdir = 'treemix/seg_%s_og_%s_ldp_%s' % ('_'.join(segpops), '_'.join(outgroups), ldp_n_iter)\n",
    "    !mkdir -pv {outdir}\n",
    "    fn = os.path.join(outdir, '%s.allele_counts.txt' % rname)\n",
    "    to_treemix(acsu, fn)\n",
    "    !gzip -fv {fn}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring values for generating my treemix file and ran on it for chromosome 3R, 3L, X, and the X region involved on speciation between <i>An.gambiae</i> and <i>An.coluzzii</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgroups = ['chri']\n",
    "segpops = ['BFcol', 'CIcol', 'GHcol', 'GNcol','GHgam', 'BFgam', 'GNgam', 'GM', 'GW']\n",
    "n = 200000\n",
    "ldp_n_iter = 1\n",
    "region_3R_24mbp = '3R-24Mbp', '3R', 1, 24_000_000\n",
    "region_3L_free = '3L-free', '3L', 18_000_000, 41_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## Treemix on 24Mbp 3R-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3R-24Mbp 3R 1 24000000\n",
      "outgroup ascertainment, initial 5760020\n",
      "chri 4113161\n",
      "ingroup ascertainment, initial 5760020\n",
      "after require segregating in BFcol 1662192\n",
      "after require segregating in CIcol 935048\n",
      "after require segregating in GHcol 745633\n",
      "after require segregating in GNcol 253224\n",
      "after require segregating in GHgam 193813\n",
      "after require segregating in BFgam 192709\n",
      "after require segregating in GNgam 189321\n",
      "after require segregating in GM 186583\n",
      "after require segregating in GW 186277\n",
      "initial ascertainment 120572\n",
      "iteration 1 retaining 86854 removing 33718 variants\n",
      "treemix/seg_BFcol_CIcol_GHcol_GNcol_GHgam_BFgam_GNgam_GM_GW_og_chri_ldp_1/3R-24Mbp.allele_counts.txt:\t 92.4% -- replaced with treemix/seg_BFcol_CIcol_GHcol_GNcol_GHgam_BFgam_GNgam_GM_GW_og_chri_ldp_1/3R-24Mbp.allele_counts.txt.gz\n"
     ]
    }
   ],
   "source": [
    "rname, chrom, start, stop = region_3R_24mbp\n",
    "log(rname, chrom, start, stop)\n",
    "run_analysis(rname, chrom, start, stop, outgroups, segpops, n=n, ldp_n_iter=ldp_n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    "## Treemix on 3L (18 Mbp to 41 Mbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3L-free 3L 18000000 41000000\n",
      "outgroup ascertainment, initial 5358122\n",
      "chri 3463220\n",
      "ingroup ascertainment, initial 5358122\n",
      "after require segregating in BFcol 1554906\n",
      "after require segregating in CIcol 865263\n",
      "after require segregating in GHcol 690085\n",
      "after require segregating in GNcol 234815\n",
      "after require segregating in GHgam 178327\n",
      "after require segregating in BFgam 177181\n",
      "after require segregating in GNgam 174069\n",
      "after require segregating in GM 171534\n",
      "after require segregating in GW 171291\n",
      "initial ascertainment 100081\n",
      "iteration 1 retaining 72112 removing 27969 variants\n",
      "treemix/seg_BFcol_CIcol_GHcol_GNcol_GHgam_BFgam_GNgam_GM_GW_og_chri_ldp_1/3L-free.allele_counts.txt:\t 92.5% -- replaced with treemix/seg_BFcol_CIcol_GHcol_GNcol_GHgam_BFgam_GNgam_GM_GW_og_chri_ldp_1/3L-free.allele_counts.txt.gz\n"
     ]
    }
   ],
   "source": [
    "rname, chrom, start, stop = region_3L_free\n",
    "log(rname, chrom, start, stop)\n",
    "run_analysis(rname, chrom, start, stop, outgroups, segpops, n=n, ldp_n_iter=ldp_n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
